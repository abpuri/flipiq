{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flip Opportunity Scoring Analysis\n",
    "\n",
    "This notebook applies the flip opportunity scoring model to identify high-potential markets.\n",
    "\n",
    "## Scoring Components:\n",
    "1. **Appreciation Score** - ZIP-level price growth (12-month lookback)\n",
    "2. **Velocity Score** - Days to pending (faster = better for flippers)\n",
    "3. **Distress Score** - Price cut percentage (higher = motivated sellers)\n",
    "4. **Pricing Power Score** - Sale-to-list ratio (lower = buyer advantage)\n",
    "5. **Value Gap Score** - Difference between all-homes and bottom-tier (renovation potential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from src.data_loader import load_all_datasets\n",
    "from src.scoring_engine import (\n",
    "    flip_opportunity_score,\n",
    "    get_score_breakdown,\n",
    "    filter_opportunities,\n",
    "    summarize_by_geography,\n",
    "    FAST_FLIP, VALUE_ADD_FLIP, BALANCED\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', 25)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('Loading datasets...')\n",
    "datasets = load_all_datasets()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Opportunity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score all ZIPs using balanced strategy\n",
    "print('Calculating flip opportunity scores...')\n",
    "print(f'Strategy: {BALANCED.name}')\n",
    "print(f'Weights: Appreciation={BALANCED.appreciation_weight}, Velocity={BALANCED.velocity_weight}, '\n",
    "      f'Distress={BALANCED.distress_weight}, Pricing={BALANCED.pricing_power_weight}, '\n",
    "      f'ValueGap={BALANCED.value_gap_weight}')\n",
    "print()\n",
    "\n",
    "scores = flip_opportunity_score(\n",
    "    datasets=datasets,\n",
    "    strategy=BALANCED,\n",
    "    min_home_value=50000,\n",
    "    max_home_value=500000\n",
    ")\n",
    "\n",
    "print(f'Total ZIPs scored: {len(scores):,}')\n",
    "print(f'Score range: {scores[\"composite_score\"].min():.1f} - {scores[\"composite_score\"].max():.1f}')\n",
    "print(f'Mean score: {scores[\"composite_score\"].mean():.1f}')\n",
    "print(f'Median score: {scores[\"composite_score\"].median():.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Top 50 Opportunity ZIPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*100)\n",
    "print('TOP 50 FLIP OPPORTUNITIES')\n",
    "print('='*100)\n",
    "\n",
    "top_50 = scores.head(50).copy()\n",
    "top_50['rank'] = range(1, 51)\n",
    "\n",
    "display_cols = ['rank', 'region_name', 'city', 'state', 'metro', \n",
    "                'current_value', 'composite_score',\n",
    "                'appreciation_score', 'velocity_score', 'distress_score']\n",
    "print(top_50[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed breakdown for top 5\n",
    "print('\\n' + '='*80)\n",
    "print('DETAILED BREAKDOWN - TOP 5 OPPORTUNITIES')\n",
    "print('='*80)\n",
    "\n",
    "for i, row in scores.head(5).iterrows():\n",
    "    print(f\"\\n#{scores.index.get_loc(i)+1}: ZIP {row['region_name']} - {row['city']}, {row['state']}\")\n",
    "    print(f\"   Metro: {row['metro']}\")\n",
    "    print(f\"   Current Value: ${row['current_value']:,.0f}\")\n",
    "    print(f\"   COMPOSITE SCORE: {row['composite_score']:.1f}/100\")\n",
    "    print(f\"   ---\")\n",
    "    print(f\"   Appreciation: {row['appreciation_score']:.1f}/100 ({row['appreciation_pct']:.1f}% 12mo growth)\")\n",
    "    print(f\"   Velocity: {row['velocity_score']:.1f}/100 ({row.get('days_to_pending', 'N/A')} days to pending)\")\n",
    "    print(f\"   Distress: {row['distress_score']:.1f}/100 ({row.get('price_cut_pct', 'N/A'):.1f}% price cuts)\")\n",
    "    print(f\"   Pricing Power: {row['pricing_power_score']:.1f}/100 ({row.get('sale_to_list', 'N/A'):.3f} sale/list)\")\n",
    "    print(f\"   Value Gap: {row['value_gap_score']:.1f}/100 ({row.get('value_gap_pct', 'N/A'):.1f}% gap)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Score Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Composite score distribution\n",
    "ax = axes[0, 0]\n",
    "ax.hist(scores['composite_score'], bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(scores['composite_score'].mean(), color='red', linestyle='--', label=f'Mean: {scores[\"composite_score\"].mean():.1f}')\n",
    "ax.axvline(scores['composite_score'].median(), color='green', linestyle='--', label=f'Median: {scores[\"composite_score\"].median():.1f}')\n",
    "ax.set_xlabel('Composite Score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Composite Score Distribution')\n",
    "ax.legend()\n",
    "\n",
    "# Component score distributions\n",
    "components = [\n",
    "    ('appreciation_score', 'Appreciation Score'),\n",
    "    ('velocity_score', 'Velocity Score'),\n",
    "    ('distress_score', 'Distress Score'),\n",
    "    ('pricing_power_score', 'Pricing Power Score'),\n",
    "    ('value_gap_score', 'Value Gap Score')\n",
    "]\n",
    "\n",
    "for idx, (col, title) in enumerate(components):\n",
    "    ax = axes[(idx+1)//3, (idx+1)%3]\n",
    "    data = scores[col].dropna()\n",
    "    ax.hist(data, bins=40, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(data.mean(), color='red', linestyle='--', alpha=0.7)\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'{title} (mean: {data.mean():.1f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/score_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: data/processed/score_distributions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary by state\n",
    "print('='*80)\n",
    "print('TOP 20 STATES BY AVERAGE OPPORTUNITY SCORE')\n",
    "print('='*80)\n",
    "\n",
    "state_summary = summarize_by_geography(scores, level='state')\n",
    "print(state_summary.head(20).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top states\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Top 15 states by average score\n",
    "ax = axes[0]\n",
    "top_states = state_summary.head(15)\n",
    "ax.barh(range(len(top_states)), top_states['avg_score'], color='steelblue')\n",
    "ax.set_yticks(range(len(top_states)))\n",
    "ax.set_yticklabels(top_states.index)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Average Opportunity Score')\n",
    "ax.set_title('Top 15 States by Avg Score')\n",
    "\n",
    "# Top 15 states by number of opportunities\n",
    "ax = axes[1]\n",
    "top_count = state_summary.sort_values('num_opportunities', ascending=False).head(15)\n",
    "ax.barh(range(len(top_count)), top_count['num_opportunities'], color='coral')\n",
    "ax.set_yticks(range(len(top_count)))\n",
    "ax.set_yticklabels(top_count.index)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Number of Opportunities')\n",
    "ax.set_title('Top 15 States by # of Opportunities')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/state_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: data/processed/state_analysis.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary by metro\n",
    "print('='*80)\n",
    "print('TOP 25 METROS BY AVERAGE OPPORTUNITY SCORE')\n",
    "print('='*80)\n",
    "\n",
    "metro_summary = summarize_by_geography(scores, level='metro')\n",
    "# Filter to metros with at least 5 ZIPs\n",
    "metro_summary_filtered = metro_summary[metro_summary['num_opportunities'] >= 5]\n",
    "print(metro_summary_filtered.head(25).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top metros visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "top_metros = metro_summary_filtered.head(20)\n",
    "colors = plt.cm.RdYlGn(top_metros['avg_score'] / 100)\n",
    "\n",
    "bars = ax.barh(range(len(top_metros)), top_metros['avg_score'], color=colors)\n",
    "ax.set_yticks(range(len(top_metros)))\n",
    "ax.set_yticklabels([m[:40] + '...' if len(m) > 40 else m for m in top_metros.index])\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Average Opportunity Score')\n",
    "ax.set_title('Top 20 Metros by Average Opportunity Score (min 5 ZIPs)')\n",
    "\n",
    "# Add count labels\n",
    "for i, (score, count) in enumerate(zip(top_metros['avg_score'], top_metros['num_opportunities'])):\n",
    "    ax.text(score + 0.5, i, f'n={count}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/metro_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: data/processed/metro_analysis.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Component Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between score components\n",
    "score_cols = ['composite_score', 'appreciation_score', 'velocity_score', \n",
    "              'distress_score', 'pricing_power_score', 'value_gap_score']\n",
    "\n",
    "corr_matrix = scores[score_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdYlGn', center=0,\n",
    "            fmt='.2f', square=True, ax=ax)\n",
    "ax.set_title('Score Component Correlations')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/score_correlations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: data/processed/score_correlations.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Strategy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different strategies\n",
    "print('='*80)\n",
    "print('STRATEGY COMPARISON')\n",
    "print('='*80)\n",
    "\n",
    "strategies = [FAST_FLIP, VALUE_ADD_FLIP, BALANCED]\n",
    "strategy_results = {}\n",
    "\n",
    "for strategy in strategies:\n",
    "    strat_scores = flip_opportunity_score(\n",
    "        datasets=datasets,\n",
    "        strategy=strategy,\n",
    "        min_home_value=50000,\n",
    "        max_home_value=500000\n",
    "    )\n",
    "    strategy_results[strategy.name] = strat_scores\n",
    "    \n",
    "    print(f\"\\n{strategy.name}:\")\n",
    "    print(f\"  Weights: App={strategy.appreciation_weight}, Vel={strategy.velocity_weight}, \"\n",
    "          f\"Dist={strategy.distress_weight}, Price={strategy.pricing_power_weight}, \"\n",
    "          f\"Gap={strategy.value_gap_weight}\")\n",
    "    print(f\"  Top 5 ZIPs:\")\n",
    "    for _, row in strat_scores.head(5).iterrows():\n",
    "        print(f\"    {row['region_name']} ({row['city']}, {row['state']}): {row['composite_score']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare top 10 ZIPs across strategies\n",
    "print('\\n' + '='*80)\n",
    "print('TOP 10 COMPARISON ACROSS STRATEGIES')\n",
    "print('='*80)\n",
    "\n",
    "comparison_df = pd.DataFrame()\n",
    "\n",
    "for name, strat_scores in strategy_results.items():\n",
    "    top10 = strat_scores.head(10)[['region_name', 'city', 'state', 'composite_score']].copy()\n",
    "    top10['strategy'] = name\n",
    "    top10['rank'] = range(1, 11)\n",
    "    comparison_df = pd.concat([comparison_df, top10])\n",
    "\n",
    "# Pivot to show side by side\n",
    "comparison_pivot = comparison_df.pivot(index='rank', columns='strategy', \n",
    "                                        values=['region_name', 'composite_score'])\n",
    "print(comparison_pivot.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Filtered Opportunity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-score opportunities (60+) with specific characteristics\n",
    "print('='*80)\n",
    "print('FILTERED OPPORTUNITIES: Score >= 65, Fast Markets (< 45 days)')\n",
    "print('='*80)\n",
    "\n",
    "fast_market_opps = filter_opportunities(\n",
    "    scores,\n",
    "    min_score=65,\n",
    "    max_days_to_pending=45\n",
    ")\n",
    "\n",
    "print(f\"Found {len(fast_market_opps):,} opportunities\")\n",
    "print()\n",
    "print(fast_market_opps.head(20)[['region_name', 'city', 'state', 'metro', \n",
    "                                  'current_value', 'composite_score', \n",
    "                                  'days_to_pending']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distressed market opportunities\n",
    "print('='*80)\n",
    "print('FILTERED OPPORTUNITIES: Score >= 60, High Distress (> 25% price cuts)')\n",
    "print('='*80)\n",
    "\n",
    "distressed_opps = filter_opportunities(\n",
    "    scores,\n",
    "    min_score=60,\n",
    "    min_price_cuts=25\n",
    ")\n",
    "\n",
    "print(f\"Found {len(distressed_opps):,} opportunities\")\n",
    "print()\n",
    "print(distressed_opps.head(20)[['region_name', 'city', 'state', 'metro', \n",
    "                                 'current_value', 'composite_score', \n",
    "                                 'price_cut_pct']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High appreciation potential\n",
    "print('='*80)\n",
    "print('FILTERED OPPORTUNITIES: Score >= 55, High Appreciation (> 5% YoY)')\n",
    "print('='*80)\n",
    "\n",
    "appreciation_opps = filter_opportunities(\n",
    "    scores,\n",
    "    min_score=55,\n",
    "    min_appreciation=5\n",
    ")\n",
    "\n",
    "print(f\"Found {len(appreciation_opps):,} opportunities\")\n",
    "print()\n",
    "print(appreciation_opps.head(20)[['region_name', 'city', 'state', 'metro', \n",
    "                                   'current_value', 'composite_score', \n",
    "                                   'appreciation_pct']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Characteristics of High-Scoring Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare characteristics: Top 20% vs Bottom 20%\n",
    "print('='*80)\n",
    "print('CHARACTERISTICS COMPARISON: TOP 20% vs BOTTOM 20%')\n",
    "print('='*80)\n",
    "\n",
    "top_20_pct = scores.head(int(len(scores) * 0.2))\n",
    "bottom_20_pct = scores.tail(int(len(scores) * 0.2))\n",
    "\n",
    "metrics = ['current_value', 'appreciation_pct', 'days_to_pending', \n",
    "           'price_cut_pct', 'sale_to_list', 'value_gap_pct']\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': metrics,\n",
    "    'Top 20% Mean': [top_20_pct[m].mean() for m in metrics],\n",
    "    'Bottom 20% Mean': [bottom_20_pct[m].mean() for m in metrics],\n",
    "    'Difference': [top_20_pct[m].mean() - bottom_20_pct[m].mean() for m in metrics]\n",
    "})\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key differentiators\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "metrics_to_plot = [\n",
    "    ('current_value', 'Home Value ($)', False),\n",
    "    ('appreciation_pct', 'Appreciation (%)', False),\n",
    "    ('days_to_pending', 'Days to Pending', False),\n",
    "    ('price_cut_pct', 'Price Cut (%)', False),\n",
    "    ('sale_to_list', 'Sale/List Ratio', False),\n",
    "    ('composite_score', 'Composite Score', True)\n",
    "]\n",
    "\n",
    "for idx, (col, title, is_score) in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx//3, idx%3]\n",
    "    \n",
    "    # Create bins based on composite score quintiles\n",
    "    scores['score_quintile'] = pd.qcut(scores['composite_score'], 5, labels=['Q1 (Low)', 'Q2', 'Q3', 'Q4', 'Q5 (High)'])\n",
    "    \n",
    "    quintile_means = scores.groupby('score_quintile')[col].mean()\n",
    "    \n",
    "    colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, 5))\n",
    "    ax.bar(range(5), quintile_means.values, color=colors)\n",
    "    ax.set_xticks(range(5))\n",
    "    ax.set_xticklabels(['Q1\\n(Low)', 'Q2', 'Q3', 'Q4', 'Q5\\n(High)'])\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_title(f'{title} by Score Quintile')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/score_quintile_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: data/processed/score_quintile_analysis.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Top Opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processed data directory if it doesn't exist\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export top 500 opportunities\n",
    "top_opportunities = scores.head(500).copy()\n",
    "top_opportunities['rank'] = range(1, 501)\n",
    "\n",
    "# Reorder columns for export\n",
    "export_cols = [\n",
    "    'rank', 'region_name', 'city', 'state', 'metro', 'county_name',\n",
    "    'current_value', 'composite_score',\n",
    "    'appreciation_score', 'velocity_score', 'distress_score',\n",
    "    'pricing_power_score', 'value_gap_score',\n",
    "    'appreciation_pct', 'days_to_pending', 'price_cut_pct', \n",
    "    'sale_to_list', 'value_gap_pct', 'strategy'\n",
    "]\n",
    "\n",
    "export_cols = [c for c in export_cols if c in top_opportunities.columns]\n",
    "top_opportunities = top_opportunities[export_cols]\n",
    "\n",
    "# Save to CSV\n",
    "output_path = output_dir / 'top_opportunities.csv'\n",
    "top_opportunities.to_csv(output_path, index=False)\n",
    "print(f'Exported top 500 opportunities to: {output_path}')\n",
    "print(f'\\nExported columns: {list(top_opportunities.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also export by strategy\n",
    "for name, strat_scores in strategy_results.items():\n",
    "    filename = f'top_opportunities_{name.lower().replace(\" \", \"_\").replace(\"-\", \"_\")}.csv'\n",
    "    filepath = output_dir / filename\n",
    "    \n",
    "    export_df = strat_scores.head(500).copy()\n",
    "    export_df['rank'] = range(1, 501)\n",
    "    export_df = export_df[[c for c in export_cols if c in export_df.columns]]\n",
    "    \n",
    "    export_df.to_csv(filepath, index=False)\n",
    "    print(f'Exported {name} top 500 to: {filepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary & Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*80)\n",
    "print('FLIP OPPORTUNITY ANALYSIS SUMMARY')\n",
    "print('='*80)\n",
    "\n",
    "print(f'''\n",
    "ANALYSIS SCOPE:\n",
    "- Total ZIPs analyzed: {len(scores):,}\n",
    "- Value range: $50,000 - $500,000\n",
    "- Time period: Latest available data (through Nov 2025)\n",
    "\n",
    "SCORE DISTRIBUTION:\n",
    "- Score range: {scores['composite_score'].min():.1f} - {scores['composite_score'].max():.1f}\n",
    "- Mean score: {scores['composite_score'].mean():.1f}\n",
    "- Median score: {scores['composite_score'].median():.1f}\n",
    "- High-opportunity ZIPs (score >= 65): {len(scores[scores['composite_score'] >= 65]):,}\n",
    "- Very high-opportunity ZIPs (score >= 75): {len(scores[scores['composite_score'] >= 75]):,}\n",
    "\n",
    "TOP PERFORMING STATES:\n",
    "''')\n",
    "for state, row in state_summary.head(5).iterrows():\n",
    "    print(f\"  {state}: {row['avg_score']:.1f} avg score, {int(row['num_opportunities'])} ZIPs\")\n",
    "\n",
    "print(f'''\n",
    "TOP PERFORMING METROS:\n",
    "''')\n",
    "for metro, row in metro_summary_filtered.head(5).iterrows():\n",
    "    print(f\"  {metro[:50]}: {row['avg_score']:.1f} avg score, {int(row['num_opportunities'])} ZIPs\")\n",
    "\n",
    "print(f'''\n",
    "KEY CHARACTERISTICS OF HIGH-SCORING AREAS:\n",
    "''')\n",
    "top_20 = scores.head(int(len(scores) * 0.2))\n",
    "print(f\"  - Avg home value: ${top_20['current_value'].mean():,.0f}\")\n",
    "print(f\"  - Avg 12-month appreciation: {top_20['appreciation_pct'].mean():.1f}%\")\n",
    "print(f\"  - Avg days to pending: {top_20['days_to_pending'].mean():.0f}\")\n",
    "print(f\"  - Avg price cuts: {top_20['price_cut_pct'].mean():.1f}%\")\n",
    "print(f\"  - Avg sale/list ratio: {top_20['sale_to_list'].mean():.3f}\")\n",
    "\n",
    "print(f'''\n",
    "EXPORTED FILES:\n",
    "- data/processed/top_opportunities.csv (Top 500 balanced strategy)\n",
    "- data/processed/top_opportunities_fast_flip.csv\n",
    "- data/processed/top_opportunities_value_add_flip.csv\n",
    "- data/processed/top_opportunities_balanced.csv\n",
    "- data/processed/score_distributions.png\n",
    "- data/processed/state_analysis.png\n",
    "- data/processed/metro_analysis.png\n",
    "- data/processed/score_correlations.png\n",
    "- data/processed/score_quintile_analysis.png\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
