{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Simulation Demo\n",
    "\n",
    "This notebook demonstrates the agentic workflow system for automated flip opportunity detection.\n",
    "\n",
    "## System Overview\n",
    "\n",
    "The agent system consists of 6 specialized agents:\n",
    "\n",
    "1. **DataRefreshAgent** - Monitors for new Zillow data releases\n",
    "2. **ScoringAgent** - Computes opportunity scores using the scoring engine\n",
    "3. **OpportunityDetectionAgent** - Identifies new and changed opportunities\n",
    "4. **PropertyAnalysisAgent** - Performs deep-dive analysis on top opportunities\n",
    "5. **AlertAgent** - Generates and manages alerts with priority classification\n",
    "6. **ReportGeneratorAgent** - Creates weekly summary reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from src.data_loader import load_all_datasets\n",
    "from src.scoring_engine import flip_opportunity_score, BALANCED\n",
    "from src.agent_workflow import AgentOrchestrator, AgentState\n",
    "from src.alert_system import AlertManager, AlertType\n",
    "from src.property_analyzer import PropertyAnalyzer\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Simulation Results\n",
    "\n",
    "If you've run the simulation (`python workflows/simulate_agent_run.py`), we can load and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load simulation results\n",
    "agent_logs_dir = Path.cwd().parent / \"data\" / \"processed\" / \"agent_logs\"\n",
    "\n",
    "# Check if simulation has been run\n",
    "if not agent_logs_dir.exists():\n",
    "    print(\"Simulation not yet run. Execute: python workflows/simulate_agent_run.py\")\n",
    "else:\n",
    "    # Load summary\n",
    "    with open(agent_logs_dir / \"simulation_summary.json\", 'r') as f:\n",
    "        summary = json.load(f)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"SIMULATION SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    for key, value in summary.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Alert Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load alerts\n",
    "with open(agent_logs_dir / \"alerts.json\", 'r') as f:\n",
    "    alerts = json.load(f)\n",
    "\n",
    "alerts_df = pd.DataFrame(alerts)\n",
    "print(f\"Total alerts loaded: {len(alerts_df)}\")\n",
    "\n",
    "# Alert priority distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart of priorities\n",
    "priority_counts = alerts_df['priority'].value_counts()\n",
    "colors = {'HOT': '#FF4444', 'WARM': '#FFA500', 'WATCH': '#FFFF00', 'INFO': '#0088FF'}\n",
    "pie_colors = [colors.get(p, '#808080') for p in priority_counts.index]\n",
    "\n",
    "axes[0].pie(priority_counts.values, labels=priority_counts.index, autopct='%1.1f%%', \n",
    "            colors=pie_colors, startangle=90)\n",
    "axes[0].set_title('Alert Priority Distribution')\n",
    "\n",
    "# Bar chart by state\n",
    "top_states = alerts_df['state'].value_counts().head(10)\n",
    "sns.barplot(x=top_states.values, y=top_states.index, ax=axes[1], palette='viridis')\n",
    "axes[1].set_xlabel('Number of Alerts')\n",
    "axes[1].set_ylabel('State')\n",
    "axes[1].set_title('Top 10 States by Alert Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Timeline Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load timeline data\n",
    "timeline = pd.read_csv(agent_logs_dir / \"timeline_data.csv\")\n",
    "timeline['date'] = pd.to_datetime(timeline['date'])\n",
    "\n",
    "print(f\"Timeline spans {len(timeline)} days\")\n",
    "print(f\"Date range: {timeline['date'].min()} to {timeline['date'].max()}\")\n",
    "\n",
    "# Plot cumulative metrics\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Cumulative opportunities and alerts\n",
    "axes[0].plot(timeline['date'], timeline['cumulative_opportunities'], \n",
    "             label='Cumulative Opportunities', color='steelblue', linewidth=2)\n",
    "axes[0].plot(timeline['date'], timeline['cumulative_alerts'], \n",
    "             label='Cumulative Alerts', color='coral', linewidth=2)\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Cumulative Opportunities and Alerts Over Time')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Daily activity\n",
    "axes[1].bar(timeline['date'], timeline['new_opportunities'], \n",
    "            label='New Opportunities', color='steelblue', alpha=0.7)\n",
    "axes[1].bar(timeline['date'], timeline['alerts_generated'], \n",
    "            label='Alerts Generated', color='coral', alpha=0.7, bottom=timeline['new_opportunities'])\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Daily Agent Activity')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. HOT Alert Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze HOT alerts\n",
    "hot_alerts = alerts_df[alerts_df['priority'] == 'HOT'].copy()\n",
    "print(f\"Total HOT alerts: {len(hot_alerts)}\")\n",
    "\n",
    "# Display top HOT alerts by score\n",
    "top_hot = hot_alerts.nlargest(10, 'current_score')[[\n",
    "    'zip_code', 'city', 'state', 'metro', 'current_score', 'current_value'\n",
    "]].copy()\n",
    "\n",
    "top_hot['current_value'] = top_hot['current_value'].apply(lambda x: f\"${x:,.0f}\")\n",
    "top_hot['current_score'] = top_hot['current_score'].round(1)\n",
    "\n",
    "print(\"\\nTop 10 HOT Alerts by Score:\")\n",
    "display(top_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score distribution of HOT alerts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Score histogram\n",
    "axes[0].hist(hot_alerts['current_score'], bins=20, color='#FF4444', edgecolor='white', alpha=0.8)\n",
    "axes[0].axvline(hot_alerts['current_score'].mean(), color='black', linestyle='--', \n",
    "                label=f'Mean: {hot_alerts[\"current_score\"].mean():.1f}')\n",
    "axes[0].set_xlabel('Score')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('HOT Alert Score Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Value distribution\n",
    "axes[1].hist(hot_alerts['current_value'] / 1000, bins=20, color='#4CAF50', edgecolor='white', alpha=0.8)\n",
    "axes[1].set_xlabel('Home Value ($K)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('HOT Alert Home Value Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Property Deep Dive Demo\n",
    "\n",
    "Use the PropertyAnalyzer to perform a comprehensive analysis on a specific ZIP code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets for analysis\n",
    "datasets = load_all_datasets()\n",
    "print(\"Datasets loaded\")\n",
    "\n",
    "# Get a top HOT alert ZIP for analysis\n",
    "sample_zip = hot_alerts.nlargest(1, 'current_score')['zip_code'].iloc[0]\n",
    "print(f\"\\nAnalyzing ZIP: {sample_zip}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = PropertyAnalyzer(datasets)\n",
    "\n",
    "# Get comprehensive analysis\n",
    "report = analyzer.analyze_zip(sample_zip)\n",
    "\n",
    "if report:\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"PROPERTY ANALYSIS REPORT: {report.zip_code}\")\n",
    "    print(f\"Location: {report.city}, {report.state}\")\n",
    "    print(f\"Metro: {report.metro}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\n--- TREND ANALYSIS ---\")\n",
    "    trend = report.trend_analysis\n",
    "    print(f\"Current Value: ${trend.current_value:,.0f}\")\n",
    "    print(f\"1-Year Ago Value: ${trend.value_1yr_ago:,.0f}\")\n",
    "    print(f\"YoY Change: {trend.yoy_change_pct:.1f}%\")\n",
    "    print(f\"Trend: {trend.trend_direction} ({trend.trend_strength})\")\n",
    "    print(f\"Volatility Score: {trend.volatility_score:.1f}\")\n",
    "    print(f\"Seasonality Detected: {trend.seasonality_detected}\")\n",
    "    \n",
    "    print(\"\\n--- MOMENTUM ---\")\n",
    "    mom = report.momentum\n",
    "    print(f\"Momentum Score: {mom.momentum_score:.1f}\")\n",
    "    print(f\"Momentum Grade: {mom.momentum_grade}\")\n",
    "    print(f\"Velocity Score: {mom.velocity_score:.1f}\")\n",
    "    print(f\"Demand Score: {mom.demand_score:.1f}\")\n",
    "    \n",
    "    print(\"\\n--- RISK ASSESSMENT ---\")\n",
    "    risk = report.risk\n",
    "    print(f\"Risk Grade: {risk.risk_grade}\")\n",
    "    print(f\"Overall Risk Score: {risk.overall_risk_score:.1f}\")\n",
    "    print(f\"Risk Factors: {', '.join(risk.risk_factors)}\")\n",
    "    \n",
    "    print(\"\\n--- INVESTMENT RECOMMENDATION ---\")\n",
    "    rec = report.recommendation\n",
    "    print(f\"Action: {rec.action}\")\n",
    "    print(f\"Confidence: {rec.confidence}\")\n",
    "    print(f\"Target Purchase Price: ${rec.target_purchase_price:,.0f}\")\n",
    "    print(f\"Estimated ARV: ${rec.estimated_arv:,.0f}\")\n",
    "    print(f\"Estimated Profit: ${rec.estimated_profit:,.0f}\")\n",
    "    print(f\"Profit Margin: {rec.profit_margin_pct:.1f}%\")\n",
    "    print(f\"Hold Period: {rec.recommended_hold_period}\")\n",
    "    print(f\"Exit Strategy: {rec.exit_strategy}\")\n",
    "else:\n",
    "    print(f\"Could not analyze ZIP {sample_zip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Agent Log Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze agent logs\n",
    "agent_names = [\n",
    "    'DataRefreshAgent',\n",
    "    'ScoringAgent',\n",
    "    'OpportunityDetectionAgent',\n",
    "    'PropertyAnalysisAgent',\n",
    "    'AlertAgent',\n",
    "    'ReportGeneratorAgent'\n",
    "]\n",
    "\n",
    "print(\"Agent Activity Summary:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for agent_name in agent_names:\n",
    "    log_file = agent_logs_dir / f\"{agent_name}_logs.json\"\n",
    "    if log_file.exists():\n",
    "        with open(log_file, 'r') as f:\n",
    "            logs = json.load(f)\n",
    "        \n",
    "        if logs:\n",
    "            completed = len([l for l in logs if l.get('status') == 'completed'])\n",
    "            print(f\"{agent_name}: {len(logs)} total runs, {completed} completed\")\n",
    "        else:\n",
    "            print(f\"{agent_name}: No logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Geographic Opportunity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze geographic distribution of opportunities\n",
    "geo_summary = alerts_df.groupby('state').agg({\n",
    "    'zip_code': 'count',\n",
    "    'current_score': 'mean',\n",
    "    'current_value': 'mean'\n",
    "}).rename(columns={\n",
    "    'zip_code': 'alert_count',\n",
    "    'current_score': 'avg_score',\n",
    "    'current_value': 'avg_value'\n",
    "}).round(1)\n",
    "\n",
    "geo_summary = geo_summary.sort_values('alert_count', ascending=False)\n",
    "\n",
    "print(\"Top 15 States by Alert Count:\")\n",
    "display(geo_summary.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metro area analysis\n",
    "metro_summary = alerts_df.groupby('metro').agg({\n",
    "    'zip_code': 'count',\n",
    "    'current_score': 'mean',\n",
    "    'current_value': 'mean'\n",
    "}).rename(columns={\n",
    "    'zip_code': 'alert_count',\n",
    "    'current_score': 'avg_score',\n",
    "    'current_value': 'avg_value'\n",
    "}).round(1)\n",
    "\n",
    "top_metros = metro_summary.nlargest(15, 'alert_count')\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors = plt.cm.RdYlGn(top_metros['avg_score'] / 100)\n",
    "bars = ax.barh(top_metros.index, top_metros['alert_count'], color=colors)\n",
    "\n",
    "ax.set_xlabel('Number of Alerts')\n",
    "ax.set_ylabel('Metro Area')\n",
    "ax.set_title('Top 15 Metro Areas by Alert Count (color = avg score)')\n",
    "\n",
    "# Add score labels\n",
    "for i, (idx, row) in enumerate(top_metros.iterrows()):\n",
    "    ax.text(row['alert_count'] + 0.5, i, f\"{row['avg_score']:.0f}\", va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Running the Agent System\n",
    "\n",
    "Here's how you can run the agent system manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Initialize the orchestrator\n",
    "from datetime import datetime\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path.cwd().parent / \"data\" / \"processed\" / \"agent_demo\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize orchestrator\n",
    "orchestrator = AgentOrchestrator(output_dir)\n",
    "print(f\"Orchestrator initialized\")\n",
    "print(f\"State: {orchestrator.state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a single agent check\n",
    "scores_df = flip_opportunity_score(\n",
    "    datasets=datasets,\n",
    "    strategy=BALANCED,\n",
    "    min_home_value=50000,\n",
    "    max_home_value=500000\n",
    ")\n",
    "\n",
    "context = {\n",
    "    'current_date': datetime.now(),\n",
    "    'state': orchestrator.state,\n",
    "    'scores_df': scores_df,\n",
    "    'previous_scores_df': None\n",
    "}\n",
    "\n",
    "# Run data refresh check\n",
    "data_result = orchestrator.data_refresh_agent.run(context)\n",
    "print(f\"Data Refresh Result: {data_result}\")\n",
    "\n",
    "# Run scoring\n",
    "scoring_result = orchestrator.scoring_agent.run(context)\n",
    "print(f\"Scoring Result: {scoring_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Simulation Results** - Loading and analyzing 90-day simulation output\n",
    "2. **Alert Analysis** - Distribution of HOT/WARM/WATCH alerts\n",
    "3. **Timeline Visualization** - Cumulative and daily activity trends\n",
    "4. **Property Deep Dive** - Comprehensive ZIP code analysis\n",
    "5. **Geographic Patterns** - State and metro-level opportunity distribution\n",
    "6. **Agent Orchestration** - Manual agent execution example\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Run the Streamlit dashboard: `streamlit run streamlit_app.py`\n",
    "- Navigate to the **Agent Monitoring** tab for interactive exploration\n",
    "- Use the **Property Deep Dive** feature to analyze specific ZIPs\n",
    "- Download alerts and timeline data for further analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
