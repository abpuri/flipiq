{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zillow Data Exploration\n",
    "\n",
    "This notebook explores the 6 Zillow Research datasets for house flipper property identification.\n",
    "\n",
    "## Datasets:\n",
    "1. **ZHVI ZIP** - ZIP-level home values (all homes)\n",
    "2. **ZHVI Bottom Tier County** - County-level undervalued segment (5th-35th percentile)\n",
    "3. **Market Heat Index** - Metro-level supply/demand indicator\n",
    "4. **Days to Pending** - Metro-level market velocity\n",
    "5. **Price Cuts** - Metro-level distress indicator\n",
    "6. **Sale to List** - Metro-level pricing power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.data_loader import (\n",
    "    load_all_datasets,\n",
    "    validate_all_datasets,\n",
    "    get_date_columns,\n",
    "    get_metadata_columns,\n",
    "    get_date_range\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "print(\"Loading all datasets...\")\n",
    "datasets = load_all_datasets()\n",
    "print(f\"Loaded {len(datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview & Validation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation summary for all datasets\n",
    "validation_summary = validate_all_datasets(datasets)\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET VALIDATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(validation_summary.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Individual Dataset Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_dataset(name, df):\n",
    "    \"\"\"Print detailed info about a dataset.\"\"\"\n",
    "    date_cols = get_date_columns(df)\n",
    "    meta_cols = get_metadata_columns(df)\n",
    "    date_start, date_end = get_date_range(df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"DATASET: {name.upper()}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Shape: {df.shape[0]:,} rows x {df.shape[1]:,} columns\")\n",
    "    print(f\"Date Range: {date_start.strftime('%Y-%m-%d')} to {date_end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Number of time periods: {len(date_cols)}\")\n",
    "    print(f\"\\nMetadata columns ({len(meta_cols)}): {meta_cols}\")\n",
    "    print(f\"\\nColumn dtypes:\")\n",
    "    print(df[meta_cols].dtypes.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 ZHVI ZIP (ZIP-Level Home Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets['zhvi_zip']\n",
    "describe_dataset('zhvi_zip', df)\n",
    "\n",
    "print(\"\\n--- Sample Rows (first 5) ---\")\n",
    "date_cols = get_date_columns(df)\n",
    "meta_cols = get_metadata_columns(df)\n",
    "# Show metadata + first 3 and last 3 date columns\n",
    "display_cols = meta_cols + date_cols[:3] + ['...'] + date_cols[-3:] if len(date_cols) > 6 else meta_cols + date_cols\n",
    "sample = df.head()[meta_cols + date_cols[:3] + date_cols[-3:]]\n",
    "print(sample.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value statistics for ZHVI ZIP\n",
    "df = datasets['zhvi_zip']\n",
    "date_cols = get_date_columns(df)\n",
    "print(\"\\n--- Home Value Statistics (across all dates) ---\")\n",
    "values = df[date_cols].values.flatten()\n",
    "values = values[~np.isnan(values)]\n",
    "print(f\"Min value: ${values.min():,.0f}\")\n",
    "print(f\"Max value: ${values.max():,.0f}\")\n",
    "print(f\"Mean value: ${values.mean():,.0f}\")\n",
    "print(f\"Median value: ${np.median(values):,.0f}\")\n",
    "print(f\"Std dev: ${values.std():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ZHVI Bottom Tier County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets['zhvi_bottom_tier']\n",
    "describe_dataset('zhvi_bottom_tier', df)\n",
    "\n",
    "print(\"\\n--- Sample Rows (first 5) ---\")\n",
    "date_cols = get_date_columns(df)\n",
    "meta_cols = get_metadata_columns(df)\n",
    "sample = df.head()[meta_cols + date_cols[:3] + date_cols[-3:]]\n",
    "print(sample.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value statistics for ZHVI Bottom Tier\n",
    "df = datasets['zhvi_bottom_tier']\n",
    "date_cols = get_date_columns(df)\n",
    "print(\"\\n--- Bottom Tier Home Value Statistics (across all dates) ---\")\n",
    "values = df[date_cols].values.flatten()\n",
    "values = values[~np.isnan(values)]\n",
    "print(f\"Min value: ${values.min():,.0f}\")\n",
    "print(f\"Max value: ${values.max():,.0f}\")\n",
    "print(f\"Mean value: ${values.mean():,.0f}\")\n",
    "print(f\"Median value: ${np.median(values):,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Market Heat Index (Metro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets['market_heat']\n",
    "describe_dataset('market_heat', df)\n",
    "\n",
    "print(\"\\n--- Sample Rows (first 5) ---\")\n",
    "date_cols = get_date_columns(df)\n",
    "meta_cols = get_metadata_columns(df)\n",
    "sample = df.head()[meta_cols + date_cols[:3] + date_cols[-3:]]\n",
    "print(sample.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market Heat statistics\n",
    "df = datasets['market_heat']\n",
    "date_cols = get_date_columns(df)\n",
    "print(\"\\n--- Market Heat Index Statistics ---\")\n",
    "values = df[date_cols].values.flatten()\n",
    "values = values[~np.isnan(values)]\n",
    "print(f\"Min: {values.min():.1f}\")\n",
    "print(f\"Max: {values.max():.1f}\")\n",
    "print(f\"Mean: {values.mean():.1f}\")\n",
    "print(f\"Median: {np.median(values):.1f}\")\n",
    "print(f\"\\nInterpretation: Higher values = hotter/more competitive market\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Days to Pending (Metro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets['days_to_pending']\n",
    "describe_dataset('days_to_pending', df)\n",
    "\n",
    "print(\"\\n--- Sample Rows (first 5) ---\")\n",
    "date_cols = get_date_columns(df)\n",
    "meta_cols = get_metadata_columns(df)\n",
    "sample = df.head()[meta_cols + date_cols[:3] + date_cols[-3:]]\n",
    "print(sample.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days to Pending statistics\n",
    "df = datasets['days_to_pending']\n",
    "date_cols = get_date_columns(df)\n",
    "print(\"\\n--- Days to Pending Statistics ---\")\n",
    "values = df[date_cols].values.flatten()\n",
    "values = values[~np.isnan(values)]\n",
    "print(f\"Min: {values.min():.0f} days\")\n",
    "print(f\"Max: {values.max():.0f} days\")\n",
    "print(f\"Mean: {values.mean():.0f} days\")\n",
    "print(f\"Median: {np.median(values):.0f} days\")\n",
    "print(f\"\\nInterpretation: Lower values = faster market velocity (homes sell quicker)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Price Cuts (Metro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets['price_cuts']\n",
    "describe_dataset('price_cuts', df)\n",
    "\n",
    "print(\"\\n--- Sample Rows (first 5) ---\")\n",
    "date_cols = get_date_columns(df)\n",
    "meta_cols = get_metadata_columns(df)\n",
    "sample = df.head()[meta_cols + date_cols[:3] + date_cols[-3:]]\n",
    "print(sample.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Cuts statistics\n",
    "df = datasets['price_cuts']\n",
    "date_cols = get_date_columns(df)\n",
    "print(\"\\n--- Price Cuts Statistics ---\")\n",
    "values = df[date_cols].values.flatten()\n",
    "values = values[~np.isnan(values)]\n",
    "print(f\"Min: {values.min()*100:.1f}%\")\n",
    "print(f\"Max: {values.max()*100:.1f}%\")\n",
    "print(f\"Mean: {values.mean()*100:.1f}%\")\n",
    "print(f\"Median: {np.median(values)*100:.1f}%\")\n",
    "print(f\"\\nInterpretation: Higher % = more price cuts = potential distress/overpricing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Sale to List Ratio (Metro) - WEEKLY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets['sale_to_list']\n",
    "describe_dataset('sale_to_list', df)\n",
    "\n",
    "print(\"\\n--- Sample Rows (first 5) ---\")\n",
    "date_cols = get_date_columns(df)\n",
    "meta_cols = get_metadata_columns(df)\n",
    "sample = df.head()[meta_cols + date_cols[:3] + date_cols[-3:]]\n",
    "print(sample.to_string())\n",
    "print(\"\\n*** NOTE: This dataset is WEEKLY, not monthly like the others ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sale to List statistics\n",
    "df = datasets['sale_to_list']\n",
    "date_cols = get_date_columns(df)\n",
    "print(\"\\n--- Sale to List Ratio Statistics ---\")\n",
    "values = df[date_cols].values.flatten()\n",
    "values = values[~np.isnan(values)]\n",
    "print(f\"Min: {values.min():.4f}\")\n",
    "print(f\"Max: {values.max():.4f}\")\n",
    "print(f\"Mean: {values.mean():.4f}\")\n",
    "print(f\"Median: {np.median(values):.4f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  > 1.0 = Homes selling ABOVE asking (seller's market)\")\n",
    "print(f\"  < 1.0 = Homes selling BELOW asking (buyer's market)\")\n",
    "print(f\"  = 1.0 = Homes selling at asking price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"MISSING VALUE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    date_cols = get_date_columns(df)\n",
    "    meta_cols = get_metadata_columns(df)\n",
    "    \n",
    "    total_cells = df.size\n",
    "    missing_total = df.isnull().sum().sum()\n",
    "    \n",
    "    # Missing in metadata vs date columns\n",
    "    missing_meta = df[meta_cols].isnull().sum().sum()\n",
    "    missing_dates = df[date_cols].isnull().sum().sum()\n",
    "    \n",
    "    # Regions with any missing date values\n",
    "    regions_with_missing = (df[date_cols].isnull().any(axis=1)).sum()\n",
    "    \n",
    "    print(f\"\\n{name.upper()}:\")\n",
    "    print(f\"  Total missing: {missing_total:,} ({missing_total/total_cells*100:.2f}%)\")\n",
    "    print(f\"  Missing in metadata columns: {missing_meta:,}\")\n",
    "    print(f\"  Missing in date columns: {missing_dates:,}\")\n",
    "    print(f\"  Regions with at least one missing value: {regions_with_missing:,} ({regions_with_missing/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Geographic Coverage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"GEOGRAPHIC COVERAGE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ZHVI ZIP coverage\n",
    "df = datasets['zhvi_zip']\n",
    "print(f\"\\nZHVI ZIP:\")\n",
    "print(f\"  Total ZIP codes: {len(df):,}\")\n",
    "print(f\"  States covered: {df['state'].nunique()}\")\n",
    "print(f\"  Metros covered: {df['metro'].dropna().nunique()}\")\n",
    "print(f\"  Counties covered: {df['county_name'].dropna().nunique()}\")\n",
    "print(f\"\\n  Top 10 states by ZIP count:\")\n",
    "print(df['state'].value_counts().head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZHVI Bottom Tier County coverage\n",
    "df = datasets['zhvi_bottom_tier']\n",
    "print(f\"\\nZHVI BOTTOM TIER COUNTY:\")\n",
    "print(f\"  Total counties: {len(df):,}\")\n",
    "print(f\"  States covered: {df['state'].nunique()}\")\n",
    "print(f\"\\n  Top 10 states by county count:\")\n",
    "print(df['state'].value_counts().head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metro-level datasets coverage\n",
    "print(f\"\\nMETRO-LEVEL DATASETS:\")\n",
    "for name in ['market_heat', 'days_to_pending', 'price_cuts', 'sale_to_list']:\n",
    "    df = datasets[name]\n",
    "    print(f\"\\n  {name.upper()}:\")\n",
    "    print(f\"    Total metros: {len(df):,}\")\n",
    "    if 'state_name' in df.columns:\n",
    "        print(f\"    States covered: {df['state_name'].dropna().nunique()}\")\n",
    "    \n",
    "    # Show sample metro names\n",
    "    print(f\"    Sample metros: {df['region_name'].head(5).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Date Range Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DATE RANGE COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "date_info = []\n",
    "for name, df in datasets.items():\n",
    "    date_cols = get_date_columns(df)\n",
    "    dates = pd.to_datetime(date_cols)\n",
    "    \n",
    "    # Determine frequency\n",
    "    if len(dates) > 1:\n",
    "        avg_gap = (dates.max() - dates.min()).days / (len(dates) - 1)\n",
    "        freq = 'Weekly' if avg_gap < 10 else 'Monthly'\n",
    "    else:\n",
    "        freq = 'Unknown'\n",
    "    \n",
    "    date_info.append({\n",
    "        'Dataset': name,\n",
    "        'Start': dates.min().strftime('%Y-%m-%d'),\n",
    "        'End': dates.max().strftime('%Y-%m-%d'),\n",
    "        'Periods': len(date_cols),\n",
    "        'Frequency': freq\n",
    "    })\n",
    "\n",
    "date_df = pd.DataFrame(date_info)\n",
    "print(date_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find overlapping date range (for analysis that combines datasets)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OVERLAPPING DATE RANGE (for multi-dataset analysis)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_starts = []\n",
    "all_ends = []\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    start, end = get_date_range(df)\n",
    "    all_starts.append(start)\n",
    "    all_ends.append(end)\n",
    "\n",
    "common_start = max(all_starts)\n",
    "common_end = min(all_ends)\n",
    "\n",
    "print(f\"All datasets overlap from: {common_start.strftime('%Y-%m-%d')} to {common_end.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Overlap duration: {(common_end - common_start).days} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Statistics for Latest Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LATEST PERIOD SUMMARY STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    date_cols = get_date_columns(df)\n",
    "    latest_col = date_cols[-1]\n",
    "    \n",
    "    print(f\"\\n{name.upper()} (as of {latest_col}):\")\n",
    "    latest_values = df[latest_col].dropna()\n",
    "    \n",
    "    if name in ['zhvi_zip', 'zhvi_bottom_tier']:\n",
    "        print(f\"  Count: {len(latest_values):,}\")\n",
    "        print(f\"  Mean: ${latest_values.mean():,.0f}\")\n",
    "        print(f\"  Median: ${latest_values.median():,.0f}\")\n",
    "        print(f\"  Min: ${latest_values.min():,.0f}\")\n",
    "        print(f\"  Max: ${latest_values.max():,.0f}\")\n",
    "        print(f\"  Std: ${latest_values.std():,.0f}\")\n",
    "    elif name == 'price_cuts':\n",
    "        print(f\"  Count: {len(latest_values):,}\")\n",
    "        print(f\"  Mean: {latest_values.mean()*100:.1f}%\")\n",
    "        print(f\"  Median: {latest_values.median()*100:.1f}%\")\n",
    "        print(f\"  Min: {latest_values.min()*100:.1f}%\")\n",
    "        print(f\"  Max: {latest_values.max()*100:.1f}%\")\n",
    "    elif name == 'sale_to_list':\n",
    "        print(f\"  Count: {len(latest_values):,}\")\n",
    "        print(f\"  Mean: {latest_values.mean():.4f}\")\n",
    "        print(f\"  Median: {latest_values.median():.4f}\")\n",
    "        print(f\"  Min: {latest_values.min():.4f}\")\n",
    "        print(f\"  Max: {latest_values.max():.4f}\")\n",
    "    else:\n",
    "        print(f\"  Count: {len(latest_values):,}\")\n",
    "        print(f\"  Mean: {latest_values.mean():.1f}\")\n",
    "        print(f\"  Median: {latest_values.median():.1f}\")\n",
    "        print(f\"  Min: {latest_values.min():.1f}\")\n",
    "        print(f\"  Max: {latest_values.max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"KEY FINDINGS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "DATA STRUCTURE:\n",
    "- All datasets use wide format with date columns (YYYY-MM-DD)\n",
    "- 5 datasets are monthly, 1 (sale_to_list) is weekly\n",
    "- Geographic levels: ZIP (1 dataset), County (1), Metro (4)\n",
    "\n",
    "GEOGRAPHIC COVERAGE:\n",
    "\"\"\")\n",
    "print(f\"- ZIP codes: {len(datasets['zhvi_zip']):,}\")\n",
    "print(f\"- Counties: {len(datasets['zhvi_bottom_tier']):,}\")\n",
    "print(f\"- Metros: ~{len(datasets['market_heat']):,}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "DATE COVERAGE:\n",
    "- ZHVI data goes back to 2000 (county) and 2022 (ZIP)\n",
    "- Market indicators available from 2018\n",
    "- All datasets extend through late 2025\n",
    "- Common overlap period: {common_start.strftime('%Y-%m-%d')} to {common_end.strftime('%Y-%m-%d')}\n",
    "\n",
    "METRICS FOR HOUSE FLIPPING ANALYSIS:\n",
    "- ZHVI: Baseline home values for ROI calculations\n",
    "- Bottom Tier: Identifies undervalued segments (flip targets)\n",
    "- Market Heat: Supply/demand indicator (timing entry/exit)\n",
    "- Days to Pending: Market velocity (holding period risk)\n",
    "- Price Cuts: Distress indicator (negotiation leverage)\n",
    "- Sale to List: Pricing power (profit margin indicator)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nNEXT STEPS:\")\n",
    "print(\"1. Merge datasets at appropriate geographic levels\")\n",
    "print(\"2. Create time series features (trends, seasonality)\")\n",
    "print(\"3. Build composite flip opportunity score\")\n",
    "print(\"4. Identify target markets and properties\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
